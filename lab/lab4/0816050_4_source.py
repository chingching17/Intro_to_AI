# -*- coding: utf-8 -*-
"""0816050_4_source.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CgsjeA0AvdRshIH6prSjf7Gs92AsJqVU

# Assignment 4: CNN

## Description

Implement a Convolutional Neural Network (CNN) classifier to predict whether a given icon image is the real / fake. Where the fake images were generated by TAs with a neural network.

- You are not required to use Colab in this assignment, but you have to **submit your source code**.

## Dataset

- https://lab.djosix.com/icons.zip
- 64x64 RGB jpg images


```
real/           (10000 images)
    0000.jpg
    0001.jpg
    ...
    9999.jpg
fake/           (10000 images)
    0000.jpg
    0001.jpg
    ...
    9999.jpg
unknown/        (5350 images, testing set)
    0000.jpg
    0001.jpg
    ...
    5349.jpg
```

- Training set
  - 20000 icons in `real/` and `fake/`
  - You should predict 1 for icons in `real/` and 0 for icons in `fake/`
- Testing set:
  - 5350 icons in `unknown/`
  - Your score depends on the **accuracy** on this testing set,  
    so the prediction of each icon in `unknown/` should be submitted (totally 5350 predictions, see below).


## Submission

Please upload **2 files** to E3. (`XXXXXXX` is your student ID)

1. **`XXXXXXX_4_result.json`**  
  This file contains your model prediction for the testing set.  
  You must generate this file with the function called `save_predictions()`.
2. **`XXXXXXX_4_source.zip`**  
  Zip your source code into this archive.


## Hints

- **Deep Learning Libraries**: You can use any deep learning frameworks (PyTorch, TensorFlow, ...).
- **How to implement**: There are many CNN examples for beginners on the internet, e.g. official websites of the above libraries, play with them and their model architectures to abtain high accuracy on testing set.
- **GPU/TPU**: Colab provides free TPU/GPU for training speedup, please refer to [this page in `pytut.pdf` on E3](https://i.imgur.com/VsrUh7I.png).

### Include this in your code to generate result file
"""

import json

def save_predictions(student_id, predictions):
  # Please use this function to generate 'XXXXXXX_4_result.json'
  # `predictions` is a list of int (0 or 1; fake=0 and real=1)
  # For example, `predictions[0]` is the prediction given "unknown/0000.jpg".
  # it will be 1 if your model think it is real, else 0 (fake).

  assert isinstance(student_id, str)
  assert isinstance(predictions, list)
  assert len(predictions) == 5350

  for y in predictions:
    assert y in (0, 1)

  with open('{}_4_result.json'.format(student_id), 'w') as f:
    json.dump(predictions, f)

import requests 
import zipfile
import os

def download_url(url, save_path, chunk_size=128):
    r = requests.get(url, stream=True)
    with open(save_path, 'wb') as fd:
        for chunk in r.iter_content(chunk_size=chunk_size):
            fd.write(chunk)
    
    with zipfile.ZipFile("icons.zip","r") as zip_ref:
      zip_ref.extractall("icons")

download_url("https://lab.djosix.com/icons.zip", "icons.zip")

import numpy as np
import pandas as pd
import keras
from keras.utils import np_utils

import numpy as np
import PIL
import glob, os

os.chdir("/content/icons/fake")
X_tr = []
Y_tr = []
for file in glob.glob("*.jpg"):
#  print(file)
  X_train_jpg = PIL.Image.open(file)
  X_train_seq = X_train_jpg.getdata()
  X_tr.append(np.reshape(np.array(X_train_seq),(64,64,3)))
  Y_tr.append(0)
# print(X_tr)
os.chdir("/content/icons/real")
for file in glob.glob("*.jpg"):
#  print(file)
  X_train_jpg = PIL.Image.open(file)
  X_train_seq = X_train_jpg.getdata()
  X_tr.append(np.reshape(np.array(X_train_seq),(64,64,3)))
  Y_tr.append(1)

X_data = np.array(X_tr)
Y_data = np.array(Y_tr)
X_data = X_data / 255

# print(X_data.shape)
# print(Y_data.shape)
# print(X_data[50])

from google.colab import drive
drive.mount('/content/drive')

from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D
from keras import layers
import numpy as np
from keras.layers.normalization import BatchNormalization
from keras.layers import GlobalAveragePooling2D,AveragePooling2D

model = Sequential()

model.add(Conv2D(filters=32,
        kernel_size=(5,5),
        padding='same',
        input_shape=(64,64,3),
        activation='relu'))

model.add(BatchNormalization())

model.add(Conv2D(filters=64,
        kernel_size=(5,5),
        padding='same',
        activation='relu'))
model.add(BatchNormalization())

# model.add(Dropout(0.25))
model.add(GlobalAveragePooling2D())
model.add(Flatten())
model.add(Dense(256, activation='relu'))
# model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

train_history=model.fit(x=X_data,
            y=Y_data,validation_split=0.2,
            epochs=20, batch_size=300, verbose=2)

os.chdir("/content/icons/unknown")
unknown_X = []
for file in glob.glob("*.jpg"):
#  print(file)
  X_train_jpg = PIL.Image.open(file)
  X_train_seq = X_train_jpg.getdata()
  unknown_X.append(np.reshape(np.array(X_train_seq),(64,64,3)))
unknown_X_array = np.array(unknown_X)
X_normalize = unknown_X_array / 255

os.chdir("/content")

prediction = model.predict_classes(X_normalize)
predictions = prediction.tolist()
# print(len(predictions), predictions)

# with open('{}_4_result.json'.format("0816050"), 'w') as f:
#   json.dump(predictions, f)

save_predictions("0816050", predictions)
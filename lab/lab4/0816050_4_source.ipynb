{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0816050_4_source.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNf1ZO4_sJK2"
      },
      "source": [
        "# Assignment 4: CNN\n",
        "\n",
        "## Description\n",
        "\n",
        "Implement a Convolutional Neural Network (CNN) classifier to predict whether a given icon image is the real / fake. Where the fake images were generated by TAs with a neural network.\n",
        "\n",
        "- You are not required to use Colab in this assignment, but you have to **submit your source code**.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "- https://lab.djosix.com/icons.zip\n",
        "- 64x64 RGB jpg images\n",
        "\n",
        "\n",
        "```\n",
        "real/           (10000 images)\n",
        "    0000.jpg\n",
        "    0001.jpg\n",
        "    ...\n",
        "    9999.jpg\n",
        "fake/           (10000 images)\n",
        "    0000.jpg\n",
        "    0001.jpg\n",
        "    ...\n",
        "    9999.jpg\n",
        "unknown/        (5350 images, testing set)\n",
        "    0000.jpg\n",
        "    0001.jpg\n",
        "    ...\n",
        "    5349.jpg\n",
        "```\n",
        "\n",
        "- Training set\n",
        "  - 20000 icons in `real/` and `fake/`\n",
        "  - You should predict 1 for icons in `real/` and 0 for icons in `fake/`\n",
        "- Testing set:\n",
        "  - 5350 icons in `unknown/`\n",
        "  - Your score depends on the **accuracy** on this testing set,  \n",
        "    so the prediction of each icon in `unknown/` should be submitted (totally 5350 predictions, see below).\n",
        "\n",
        "\n",
        "## Submission\n",
        "\n",
        "Please upload **2 files** to E3. (`XXXXXXX` is your student ID)\n",
        "\n",
        "1. **`XXXXXXX_4_result.json`**  \n",
        "  This file contains your model prediction for the testing set.  \n",
        "  You must generate this file with the function called `save_predictions()`.\n",
        "2. **`XXXXXXX_4_source.zip`**  \n",
        "  Zip your source code into this archive.\n",
        "\n",
        "\n",
        "## Hints\n",
        "\n",
        "- **Deep Learning Libraries**: You can use any deep learning frameworks (PyTorch, TensorFlow, ...).\n",
        "- **How to implement**: There are many CNN examples for beginners on the internet, e.g. official websites of the above libraries, play with them and their model architectures to abtain high accuracy on testing set.\n",
        "- **GPU/TPU**: Colab provides free TPU/GPU for training speedup, please refer to [this page in `pytut.pdf` on E3](https://i.imgur.com/VsrUh7I.png).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j94Kc1dsLaR"
      },
      "source": [
        "### Include this in your code to generate result file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUgYOZfUMvxl"
      },
      "source": [
        "import json\n",
        "\n",
        "def save_predictions(student_id, predictions):\n",
        "  # Please use this function to generate 'XXXXXXX_4_result.json'\n",
        "  # `predictions` is a list of int (0 or 1; fake=0 and real=1)\n",
        "  # For example, `predictions[0]` is the prediction given \"unknown/0000.jpg\".\n",
        "  # it will be 1 if your model think it is real, else 0 (fake).\n",
        "\n",
        "  assert isinstance(student_id, str)\n",
        "  assert isinstance(predictions, list)\n",
        "  assert len(predictions) == 5350\n",
        "\n",
        "  for y in predictions:\n",
        "    assert y in (0, 1)\n",
        "\n",
        "  with open('{}_4_result.json'.format(student_id), 'w') as f:\n",
        "    json.dump(predictions, f)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf7zjf5eV-B8"
      },
      "source": [
        "import requests \n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def download_url(url, save_path, chunk_size=128):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(save_path, 'wb') as fd:\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "            fd.write(chunk)\n",
        "    \n",
        "    with zipfile.ZipFile(\"icons.zip\",\"r\") as zip_ref:\n",
        "      zip_ref.extractall(\"icons\")\n",
        "\n",
        "download_url(\"https://lab.djosix.com/icons.zip\", \"icons.zip\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnzjqAaakHDr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6wE3VdamD9F"
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "import glob, os\n",
        "\n",
        "os.chdir(\"/content/icons/fake\")\n",
        "X_tr = []\n",
        "Y_tr = []\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "#  print(file)\n",
        "  X_train_jpg = PIL.Image.open(file)\n",
        "  X_train_seq = X_train_jpg.getdata()\n",
        "  X_tr.append(np.reshape(np.array(X_train_seq),(64,64,3)))\n",
        "  Y_tr.append(0)\n",
        "# print(X_tr)\n",
        "os.chdir(\"/content/icons/real\")\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "#  print(file)\n",
        "  X_train_jpg = PIL.Image.open(file)\n",
        "  X_train_seq = X_train_jpg.getdata()\n",
        "  X_tr.append(np.reshape(np.array(X_train_seq),(64,64,3)))\n",
        "  Y_tr.append(1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slA1Eei4yLxV"
      },
      "source": [
        "X_data = np.array(X_tr)\n",
        "Y_data = np.array(Y_tr)\n",
        "X_data = X_data / 255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7RScYgIyiKk"
      },
      "source": [
        "# print(X_data.shape)\n",
        "# print(Y_data.shape)\n",
        "# print(X_data[50])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIrwk8aErXaT",
        "outputId": "86317bc3-991c-4dfd-9c24-3924bcf5b061"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSdA3fHWxRPe",
        "outputId": "67981098-11c8-4159-bee1-b3a38a0acb20"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D,AveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32,\n",
        "        kernel_size=(5,5),\n",
        "        padding='same',\n",
        "        input_shape=(64,64,3),\n",
        "        activation='relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=64,\n",
        "        kernel_size=(5,5),\n",
        "        padding='same',\n",
        "        activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "train_history=model.fit(x=X_data,\n",
        "            y=Y_data,validation_split=0.2,\n",
        "            epochs=20, batch_size=300, verbose=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "54/54 - 54s - loss: 0.3316 - accuracy: 0.8622 - val_loss: 0.0689 - val_accuracy: 0.9955\n",
            "Epoch 2/20\n",
            "54/54 - 6s - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.9908 - val_accuracy: 0.4027\n",
            "Epoch 3/20\n",
            "54/54 - 6s - loss: 0.0015 - accuracy: 0.9998 - val_loss: 2.4736 - val_accuracy: 0.0018\n",
            "Epoch 4/20\n",
            "54/54 - 6s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 4.4152 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "54/54 - 6s - loss: 7.7866e-04 - accuracy: 0.9999 - val_loss: 7.2099 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "54/54 - 6s - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0171 - val_accuracy: 0.9927\n",
            "Epoch 7/20\n",
            "54/54 - 6s - loss: 2.8875e-04 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9772\n",
            "Epoch 8/20\n",
            "54/54 - 6s - loss: 1.5596e-04 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9952\n",
            "Epoch 9/20\n",
            "54/54 - 6s - loss: 1.0218e-04 - accuracy: 1.0000 - val_loss: 8.4673e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "54/54 - 6s - loss: 3.0650e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9965\n",
            "Epoch 11/20\n",
            "54/54 - 6s - loss: 9.6184e-05 - accuracy: 1.0000 - val_loss: 7.3445e-07 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "54/54 - 6s - loss: 3.9534e-05 - accuracy: 1.0000 - val_loss: 4.1723e-10 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "54/54 - 6s - loss: 4.2487e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9987\n",
            "Epoch 14/20\n",
            "54/54 - 6s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 10.7114 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "54/54 - 6s - loss: 1.6551e-04 - accuracy: 1.0000 - val_loss: 4.2738 - val_accuracy: 0.0072\n",
            "Epoch 16/20\n",
            "54/54 - 6s - loss: 3.7995e-05 - accuracy: 1.0000 - val_loss: 3.3801e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "54/54 - 6s - loss: 2.8419e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
            "Epoch 18/20\n",
            "54/54 - 6s - loss: 3.5972e-05 - accuracy: 1.0000 - val_loss: 6.2585e-10 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "54/54 - 6s - loss: 1.9881e-05 - accuracy: 1.0000 - val_loss: 2.1875e-08 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "54/54 - 6s - loss: 1.8699e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qSdS42Jeeu"
      },
      "source": [
        "os.chdir(\"/content/icons/unknown\")\n",
        "unknown_X = []\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "#  print(file)\n",
        "  X_train_jpg = PIL.Image.open(file)\n",
        "  X_train_seq = X_train_jpg.getdata()\n",
        "  unknown_X.append(np.reshape(np.array(X_train_seq),(64,64,3)))\n",
        "unknown_X_array = np.array(unknown_X)\n",
        "X_normalize = unknown_X_array / 255"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0Jo2pc-RV_a",
        "outputId": "39a094f5-d20b-429c-c98d-c8bd1da46e3e"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "\n",
        "prediction = model.predict_classes(X_normalize)\n",
        "predictions = prediction.tolist()\n",
        "# print(len(predictions), predictions)\n",
        "\n",
        "# with open('{}_4_result.json'.format(\"0816050\"), 'w') as f:\n",
        "#   json.dump(predictions, f)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxmNA2RZeQqh"
      },
      "source": [
        "save_predictions(\"0816050\", predictions)\n"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}